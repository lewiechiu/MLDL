{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.special import softmax\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Q-learning Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen = 2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1  # exploration rate\n",
    "        self.epsilon_min = 0.15\n",
    "        self.epsilon_decay = 0.9995\n",
    "        self.model = self._build_model()\n",
    "        self.walk = deque(maxlen = 900)\n",
    "        \n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(100, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(self.action_size, activation='softmax'))\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "#         print(state)\n",
    "#         print(reward)\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            chose = np.random.randint(0,4)\n",
    "            return chose\n",
    "        \n",
    "        act_values = 0\n",
    "        act_values = self.model.predict(state)\n",
    "        chose = np.argmax(act_values)\n",
    "#         print(act_values, chose)\n",
    "        if chose == 0:\n",
    "            return chose\n",
    "        if chose == 1:\n",
    "            return chose\n",
    "        if chose == 2:\n",
    "            return chose\n",
    "        if chose == 3:\n",
    "            return chose\n",
    "        return act_values\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        xs = []\n",
    "        ys = []\n",
    "        \n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "\n",
    "            if not done:\n",
    "#                 if reward >= 0:\n",
    "                \n",
    "                target = reward + np.multiply (self.gamma , self.model.predict(next_state)[0] )\n",
    "#                 else:\n",
    "#                     target = np.multiply (-1 , self.model.predict(next_state)[0] )\n",
    "            else:\n",
    "                target = np.multiply (self.gamma , self.model.predict(next_state)[0] )\n",
    "#             print(target)\n",
    "\n",
    "            xs.append(state[0])\n",
    "\n",
    "            ys.append(target)\n",
    "#             ys = np.array(ys)\n",
    "#             print(ys.shape)\n",
    "        xs = np.array(xs)\n",
    "        ys = np.array(ys)\n",
    "        self.model.fit(xs, ys, epochs= 1, verbose=0 , batch_size=batch_size)\n",
    "                \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        random.shuffle(self.memory)\n",
    "#         self.memory = deque(self.memory)\n",
    "        \n",
    "        \n",
    "        if np.random.rand() > 0.8:\n",
    "            self.memory.pop()\n",
    "\n",
    "    \n",
    "    def save_model(self):\n",
    "        self.model.save('./checkpoint.h5')\n",
    "        np.save(\"game_memory\", self.memory)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model.load_weights('./checkpoint.h5')\n",
    "        self.memory = np.load(\"game_memory.npy\", allow_pickle=True)\n",
    "        self.memory = deque(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_consec_300(x):\n",
    "    cnt = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] >= 300:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            cnt = 0\n",
    "    return cnt\n",
    "\n",
    "def reward_greater(rew, no_improve):\n",
    "    if rew < 0:\n",
    "        no_improve += 1\n",
    "    else:\n",
    "        no_improve = 0\n",
    "    return no_improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 22,704\n",
      "Trainable params: 22,104\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "round:0 score: -61.10305178477396 mean:-30.55152589238698 len of mem:115 spent:0.021738290786743164\n",
      "round:1 score: -43.92627066876149 mean:-35.00977415117848 len of mem:206 spent:0.01699995994567871\n",
      "round:2 score: -123.56595350003013 mean:-57.1488189883914 len of mem:291 spent:0.01638054847717285\n",
      "round:3 score: -1.6368192609726027 mean:-46.04641904290764 len of mem:380 spent:0.01738595962524414\n",
      "round:4 score: -7.639282904358917 mean:-39.64522968648285 len of mem:469 spent:0.019430875778198242\n",
      "round:5 score: 29.726186984749333 mean:-29.73502730487825 len of mem:529 spent:0.008946895599365234\n",
      "round:6 score: -4.789602794761045 mean:-26.6168492411136 len of mem:619 spent:0.014013528823852539\n",
      "round:7 score: -41.788525536356445 mean:-28.302591051696137 len of mem:699 spent:0.012790918350219727\n",
      "round:8 score: -14.128416099440276 mean:-26.88517355647055 len of mem:794 spent:0.017935514450073242\n",
      "round:9 score: 4.1651917766228355 mean:-24.062413071643878 len of mem:866 spent:0.011638164520263672\n",
      "round:10 score: -85.9163167316844 mean:-29.21690504331392 len of mem:926 spent:0.010276079177856445\n",
      "WARNING:tensorflow:From /home/louiechiu/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "round:11 score: -315.17360549137663 mean:-51.21357430854951 len of mem:1006 spent:2.4285120964050293\n",
      "round:12 score: -47.14994374744765 mean:-50.923314982756516 len of mem:1089 spent:4.706664085388184\n",
      "round:13 score: -242.3650063604612 mean:-63.68609440793683 len of mem:1150 spent:3.432194948196411\n",
      "round:14 score: -267.99019637713684 mean:-76.45510078101185 len of mem:1228 spent:4.27691650390625\n",
      "round:15 score: -152.02287322233852 mean:-80.90026386579578 len of mem:1309 spent:4.683143138885498\n",
      "round:16 score: -139.20408281689356 mean:-84.13936491863454 len of mem:1422 spent:6.206939458847046\n",
      "round:17 score: -214.4348135546856 mean:-90.99702011000565 len of mem:1487 spent:3.6845011711120605\n",
      "round:18 score: -163.4072286367431 mean:-94.61753053634253 len of mem:1613 spent:6.8089985847473145\n",
      "round:19 score: -244.3093022875737 mean:-101.745710143544 len of mem:1697 spent:4.7839930057525635\n",
      "round:20 score: -350.62922494830514 mean:-113.05859718012404 len of mem:1805 spent:5.543452262878418\n",
      "round:21 score: -219.2456615664798 mean:-117.67542606648733 len of mem:1850 spent:2.487929582595825\n",
      "round:22 score: -319.53129517624296 mean:-126.08608727939382 len of mem:1930 spent:4.569122314453125\n",
      "round:23 score: -26.923334575552044 mean:-122.11957717124014 len of mem:2000 spent:5.11311411857605\n",
      "round:24 score: -232.51513035758867 mean:-126.3655599860997 len of mem:2000 spent:3.4805023670196533\n",
      "round:25 score: -324.6488595565865 mean:-133.70938589611774 len of mem:2000 spent:5.31678318977356\n",
      "round:26 score: -387.6594807823076 mean:-142.77903214205307 len of mem:2000 spent:4.106416940689087\n",
      "round:27 score: -146.66926204677554 mean:-142.9131780008366 len of mem:2000 spent:2.8261358737945557\n",
      "round:28 score: -93.3524871191889 mean:-141.26115497144835 len of mem:2000 spent:3.1016571521759033\n",
      "round:29 score: -38.77915956957171 mean:-137.95528415203296 len of mem:2000 spent:2.4849531650543213\n",
      "round:30 score: -508.81522611356365 mean:-149.5446573383308 len of mem:2000 spent:3.1531143188476562\n",
      "round:31 score: -76.5819201357783 mean:-147.33366530188982 len of mem:2000 spent:2.862032651901245\n",
      "round:32 score: -283.18578752646516 mean:-151.3293159555538 len of mem:2000 spent:2.4778780937194824\n",
      "round:33 score: -447.59204143886444 mean:-159.79396525507696 len of mem:2000 spent:3.2066268920898438\n",
      "round:34 score: -524.7908891060828 mean:-169.93276869538266 len of mem:2000 spent:7.034272193908691\n",
      "round:35 score: -447.90876837137284 mean:-177.4456335514905 len of mem:2000 spent:2.7713117599487305\n",
      "round:36 score: -406.19254836122076 mean:-183.46528920437814 len of mem:2000 spent:2.983579158782959\n",
      "round:37 score: -299.63860399124343 mean:-186.44409214763107 len of mem:2000 spent:2.658834457397461\n",
      "round:38 score: -425.54445595341315 mean:-192.4216012427757 len of mem:2000 spent:2.834324836730957\n",
      "round:39 score: -224.13238110647913 mean:-193.19503489798797 len of mem:2000 spent:2.391399383544922\n",
      "round:40 score: -174.92311564952067 mean:-192.75998920159589 len of mem:2000 spent:2.2572646141052246\n",
      "round:41 score: -486.8028049274473 mean:-199.59819421847618 len of mem:2000 spent:2.6271626949310303\n",
      "round:42 score: -320.0880062025755 mean:-202.3365990362966 len of mem:2000 spent:2.638117551803589\n",
      "round:43 score: -185.5627246462268 mean:-201.96384627207283 len of mem:2000 spent:2.404705286026001\n",
      "round:44 score: -590.3872787970993 mean:-210.40783393566036 len of mem:2000 spent:5.279693603515625\n",
      "round:45 score: -688.0200865163456 mean:-220.56979675652602 len of mem:2000 spent:5.412710905075073\n",
      "round:46 score: -482.60231196392897 mean:-226.02880749001358 len of mem:2000 spent:3.2594330310821533\n",
      "round:47 score: -572.1474912194416 mean:-233.09245409673656 len of mem:2000 spent:7.360713481903076\n",
      "round:48 score: -331.52918865657824 mean:-235.0611887879334 len of mem:2000 spent:2.7267274856567383\n",
      "round:49 score: -250.71788082762305 mean:-235.36818274949596 len of mem:2000 spent:2.675346851348877\n",
      "round:50 score: -412.9967197653215 mean:-238.78411615364647 len of mem:2000 spent:3.7025346755981445\n",
      "round:51 score: -482.94171320574674 mean:-243.390863267837 len of mem:2000 spent:3.6780505180358887\n",
      "round:52 score: -414.927111798312 mean:-246.56746046284582 len of mem:2000 spent:3.1666622161865234\n",
      "round:53 score: -810.4148795157524 mean:-256.8192317183532 len of mem:2000 spent:6.375127077102661\n",
      "round:54 score: -1815.5801415732822 mean:-284.6542479657627 len of mem:2000 spent:11.251523494720459\n",
      "round:55 score: -349.50588277979097 mean:-285.79199594495617 len of mem:2000 spent:3.2696783542633057\n",
      "round:56 score: -483.3815964933698 mean:-289.1987131957909 len of mem:2000 spent:2.9446544647216797\n",
      "round:57 score: -386.7905140400083 mean:-290.8528115151844 len of mem:2000 spent:4.122620344161987\n",
      "round:58 score: -353.04834973031956 mean:-291.88940381877 len of mem:2000 spent:2.721641778945923\n",
      "round:59 score: -265.8228947564357 mean:-291.46208399807597 len of mem:2000 spent:2.4575107097625732\n",
      "round:60 score: -504.36177811052175 mean:-294.89595003214765 len of mem:2000 spent:2.995025157928467\n",
      "round:61 score: -593.5226649842531 mean:-299.636056618689 len of mem:2000 spent:3.198723077774048\n",
      "round:62 score: -496.4617986418471 mean:-302.7114588378008 len of mem:2000 spent:2.98038911819458\n",
      "round:63 score: -369.7848693447166 mean:-303.7433574609841 len of mem:2000 spent:2.6205263137817383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:64 score: -1401.9226415438673 mean:-320.382437522846 len of mem:2000 spent:9.805177211761475\n",
      "round:65 score: -773.7531139372499 mean:-327.14916403649386 len of mem:2000 spent:7.098021507263184\n",
      "round:66 score: -433.7188729192025 mean:-328.71636563771017 len of mem:2000 spent:3.2035703659057617\n",
      "round:67 score: -1017.528446044532 mean:-338.6991494117221 len of mem:2000 spent:7.3602495193481445\n",
      "round:68 score: -567.2580488456108 mean:-341.96427654649193 len of mem:2000 spent:6.085119724273682\n",
      "round:69 score: -464.14967171637477 mean:-343.68519760522264 len of mem:2000 spent:4.826169490814209\n",
      "round:70 score: -376.5187334080079 mean:-344.1412189358169 len of mem:2000 spent:4.233399391174316\n",
      "round:71 score: -391.1215332876736 mean:-344.7847848858423 len of mem:2000 spent:3.5214953422546387\n",
      "round:72 score: -443.19287075644 mean:-346.11462388409365 len of mem:2000 spent:2.7572073936462402\n",
      "round:73 score: -1972.042085441539 mean:-367.7936567048596 len of mem:2000 spent:12.619820833206177\n",
      "round:74 score: -332.4025539329999 mean:-367.3279842999667 len of mem:2000 spent:2.60870623588562\n",
      "round:75 score: -534.9682923377914 mean:-369.5051311576008 len of mem:2000 spent:5.368883371353149\n",
      "round:76 score: -519.3814961651293 mean:-371.42662301667167 len of mem:2000 spent:4.675826549530029\n",
      "round:77 score: -325.8725908028104 mean:-370.8499896975089 len of mem:2000 spent:2.5915563106536865\n",
      "round:78 score: -1289.0240734538036 mean:-382.3271657444626 len of mem:2000 spent:10.36819338798523\n",
      "round:79 score: -1589.3541115745359 mean:-397.22873297693263 len of mem:2000 spent:10.980614185333252\n",
      "round:80 score: -351.74764212106413 mean:-396.6740855274708 len of mem:2000 spent:3.712925672531128\n",
      "round:81 score: -493.0744748845473 mean:-397.83553600165243 len of mem:2000 spent:3.748866081237793\n",
      "round:82 score: -500.9886791631657 mean:-399.06354961071804 len of mem:2000 spent:6.200695514678955\n",
      "round:83 score: -346.36453304869616 mean:-398.44356118057664 len of mem:2000 spent:2.3981802463531494\n",
      "round:84 score: -385.9418685137096 mean:-398.29819266119443 len of mem:2000 spent:5.154791593551636\n",
      "round:85 score: -198.39423433292896 mean:-396.00044601374304 len of mem:2000 spent:2.334177255630493\n",
      "round:86 score: -342.0336846928807 mean:-395.3871873623697 len of mem:2000 spent:2.504413366317749\n",
      "round:87 score: -431.12618595799415 mean:-395.788749144343 len of mem:2000 spent:4.036082983016968\n",
      "round:88 score: -456.3575101186142 mean:-396.4617353773905 len of mem:2000 spent:2.807874917984009\n",
      "round:89 score: -2054.2247601693734 mean:-414.67891147400564 len of mem:2000 spent:13.882200002670288\n",
      "round:90 score: -1344.0725827123272 mean:-424.7810165961613 len of mem:2000 spent:9.43618369102478\n",
      "round:91 score: -475.4665071743003 mean:-425.32602187119505 len of mem:2000 spent:4.469608783721924\n",
      "round:92 score: -374.5398448031346 mean:-424.7857433917476 len of mem:2000 spent:4.628179550170898\n",
      "round:93 score: -679.7832440362779 mean:-427.4699276090584 len of mem:2000 spent:5.908135175704956\n",
      "round:94 score: -624.320934522499 mean:-429.5204589310735 len of mem:2000 spent:5.092735767364502\n",
      "round:95 score: -1282.0391408826708 mean:-438.30931132232706 len of mem:2000 spent:9.840505123138428\n",
      "round:96 score: -1230.8460060064226 mean:-446.3964204517566 len of mem:2000 spent:9.747973203659058\n",
      "round:97 score: -438.6072149671039 mean:-446.31774160847726 len of mem:2000 spent:3.6572084426879883\n",
      "round:98 score: -404.07506121001853 mean:-445.89531480449267 len of mem:2000 spent:3.4147701263427734\n",
      "round:99 score: -649.306087403542 mean:-447.9092828500278 len of mem:2000 spent:6.408560752868652\n",
      "round:100 score: -657.9145133370816 mean:-449.96815765872446 len of mem:2000 spent:6.188896179199219\n",
      "round:101 score: -273.1420214699454 mean:-448.2513990549499 len of mem:2000 spent:2.259730100631714\n",
      "round:102 score: -363.76528947904904 mean:-447.43903261672006 len of mem:2000 spent:4.064081430435181\n",
      "round:103 score: -503.0536587211564 mean:-447.9686957224766 len of mem:2000 spent:4.429872512817383\n",
      "round:104 score: -590.722399157364 mean:-449.3154287737491 len of mem:2000 spent:5.84029221534729\n",
      "round:105 score: -469.89862968318704 mean:-449.50779513738865 len of mem:2000 spent:4.5020060539245605\n",
      "round:106 score: -465.7174934340742 mean:-449.657884936432 len of mem:2000 spent:4.1538543701171875\n",
      "round:107 score: -616.7641796323067 mean:-451.19097020887125 len of mem:2000 spent:5.961827754974365\n",
      "round:108 score: -866.2604010717637 mean:-454.96432867126117 len of mem:2000 spent:8.548618793487549\n",
      "round:109 score: -634.8126328071692 mean:-456.58458366347656 len of mem:2000 spent:6.766362428665161\n",
      "round:110 score: -316.21002826426496 mean:-455.3312394188409 len of mem:2000 spent:3.965454339981079\n",
      "round:111 score: -468.3841073981399 mean:-455.44675152485235 len of mem:2000 spent:4.711653232574463\n",
      "round:112 score: -422.53305391139594 mean:-455.15803487912024 len of mem:2000 spent:6.654865503311157\n",
      "round:113 score: -385.5329959889341 mean:-454.55259975833604 len of mem:2000 spent:3.2604761123657227\n",
      "round:114 score: -1530.0383123994366 mean:-463.82402831558693 len of mem:2000 spent:11.11849069595337\n",
      "round:115 score: -397.8360521031545 mean:-463.2600285188995 len of mem:2000 spent:4.363198518753052\n",
      "round:116 score: -387.1568615900797 mean:-462.6150864262824 len of mem:2000 spent:6.094295263290405\n",
      "round:117 score: -576.8575264616758 mean:-463.5751069307815 len of mem:2000 spent:5.179932117462158\n",
      "round:118 score: -542.9161375301134 mean:-464.23628218577585 len of mem:2000 spent:4.889274597167969\n",
      "round:119 score: -437.3919235574984 mean:-464.0144279822364 len of mem:2000 spent:4.6230268478393555\n",
      "round:120 score: -371.97945856364265 mean:-463.260042987002 len of mem:2000 spent:4.551990270614624\n",
      "round:121 score: -504.2545540078794 mean:-463.5933316944888 len of mem:2000 spent:5.54741358757019\n",
      "round:122 score: -1367.6722509673104 mean:-470.8842907208825 len of mem:2000 spent:9.621431827545166\n",
      "round:123 score: -312.64702548534166 mean:-469.6183925989982 len of mem:2000 spent:3.6963844299316406\n",
      "round:124 score: -523.6748400938208 mean:-470.0474120235603 len of mem:2000 spent:5.9025719165802\n",
      "round:125 score: -336.859228182501 mean:-468.99868616654413 len of mem:2000 spent:4.044666051864624\n",
      "round:126 score: -559.5162645279198 mean:-469.7058547474923 len of mem:2000 spent:6.8865838050842285\n",
      "round:127 score: -691.8316708616941 mean:-471.4277602987652 len of mem:2000 spent:6.178529977798462\n",
      "round:128 score: -414.53761974808145 mean:-470.99014383299067 len of mem:2000 spent:3.5308868885040283\n",
      "round:129 score: -490.0517050834113 mean:-471.1356519341389 len of mem:2000 spent:4.386544227600098\n",
      "round:130 score: -583.1190789509103 mean:-471.9840112297205 len of mem:2000 spent:3.9254674911499023\n",
      "round:131 score: -309.98369203898 mean:-470.76596371700816 len of mem:2000 spent:3.5751471519470215\n",
      "round:132 score: -505.56744227137807 mean:-471.0256762435333 len of mem:2000 spent:5.416486024856567\n",
      "round:133 score: -540.1570903314039 mean:-471.5377607923324 len of mem:2000 spent:4.663243532180786\n",
      "round:134 score: -387.9838181148388 mean:-470.92339356676257 len of mem:2000 spent:4.120454788208008\n",
      "round:135 score: -417.1625074691961 mean:-470.53097833977307 len of mem:2000 spent:4.157117605209351\n",
      "round:136 score: -691.7095684427921 mean:-472.13372174631667 len of mem:2000 spent:5.683711290359497\n",
      "round:137 score: -584.3848303699888 mean:-472.94128367886105 len of mem:2000 spent:4.247240304946899\n",
      "round:138 score: -1502.766579281109 mean:-480.29717864744845 len of mem:2000 spent:13.519842147827148\n",
      "round:139 score: -385.56260731520115 mean:-479.62530225502127 len of mem:2000 spent:3.8712637424468994\n",
      "round:140 score: -371.13965589181726 mean:-478.8613188299283 len of mem:2000 spent:4.004006862640381\n",
      "round:141 score: -1707.612868678819 mean:-487.45398701068973 len of mem:2000 spent:12.04651427268982\n",
      "round:142 score: -398.46916027410094 mean:-486.836036825019 len of mem:2000 spent:3.8267555236816406\n",
      "round:143 score: -2345.7040333284103 mean:-499.6558161112493 len of mem:2000 spent:13.324506282806396\n",
      "round:144 score: -396.65312984508967 mean:-498.9503182601112 len of mem:2000 spent:4.8685173988342285\n",
      "round:145 score: -319.7551560287495 mean:-497.7313035510542 len of mem:2000 spent:3.3782784938812256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:146 score: -977.2921198561788 mean:-500.9715793368997 len of mem:2000 spent:10.22830080986023\n",
      "round:147 score: -1312.6901845822758 mean:-506.4193552110298 len of mem:2000 spent:9.172417879104614\n",
      "round:148 score: -274.8997460188631 mean:-504.87589114974867 len of mem:2000 spent:3.6550567150115967\n",
      "round:149 score: -829.6118788904614 mean:-507.02646060498523 len of mem:2000 spent:6.786843776702881\n",
      "round:150 score: -398.13636202409504 mean:-506.3100783774794 len of mem:2000 spent:6.630048036575317\n",
      "round:151 score: -694.9132634217635 mean:-507.5427789333243 len of mem:2000 spent:6.056920051574707\n",
      "round:152 score: -490.2902523212167 mean:-507.4307495397393 len of mem:2000 spent:4.002099990844727\n",
      "round:153 score: -392.0087941650861 mean:-506.6860917631286 len of mem:2000 spent:3.711543083190918\n",
      "round:154 score: -469.4830912814146 mean:-506.4476109908099 len of mem:2000 spent:3.9236085414886475\n",
      "round:155 score: -334.0165557888094 mean:-505.34932401500095 len of mem:2000 spent:4.110081911087036\n",
      "round:156 score: -990.4071480071187 mean:-508.4193102427992 len of mem:2000 spent:7.575557708740234\n",
      "round:157 score: -357.1672729050544 mean:-507.468039567719 len of mem:2000 spent:4.67029881477356\n",
      "round:158 score: -1360.38991242256 mean:-512.7988012730618 len of mem:2000 spent:10.278234004974365\n",
      "round:159 score: -476.0096578435208 mean:-512.570297276605 len of mem:2000 spent:4.059844732284546\n",
      "round:160 score: -543.4277485656909 mean:-512.7607753709821 len of mem:2000 spent:4.514482498168945\n",
      "round:161 score: -573.3150156689442 mean:-513.132273777718 len of mem:2000 spent:6.715498447418213\n",
      "round:162 score: -293.4818597917602 mean:-511.7929419851207 len of mem:2000 spent:4.258465051651001\n",
      "round:163 score: -418.5676398628697 mean:-511.22794015407686 len of mem:2000 spent:3.193506956100464\n",
      "round:164 score: -494.11619763666124 mean:-511.12485736782736 len of mem:2000 spent:5.085026025772095\n",
      "round:165 score: -422.90535436358346 mean:-510.5965968707959 len of mem:2000 spent:3.3735084533691406\n",
      "round:166 score: -473.16916285132817 mean:-510.3738145254419 len of mem:2000 spent:3.6056864261627197\n",
      "round:167 score: -446.27962097653386 mean:-509.9945589423123 len of mem:2000 spent:3.4623019695281982\n",
      "round:168 score: -583.4337113540249 mean:-510.4265539564988 len of mem:2000 spent:5.316827774047852\n",
      "round:169 score: -329.90336280423617 mean:-509.37086278016983 len of mem:2000 spent:3.5599663257598877\n",
      "round:170 score: -538.3436071186695 mean:-509.5393089681844 len of mem:2000 spent:3.8839669227600098\n",
      "round:171 score: -444.0916216819061 mean:-509.16099863704983 len of mem:2000 spent:4.146538019180298\n",
      "round:172 score: -881.9768861861243 mean:-511.3036186804353 len of mem:2000 spent:6.672539234161377\n",
      "round:173 score: -451.8577486653272 mean:-510.96392799463473 len of mem:2000 spent:3.981726884841919\n",
      "round:174 score: -855.096282817438 mean:-512.9192254652188 len of mem:2000 spent:8.977851867675781\n",
      "round:175 score: -352.7786358730953 mean:-512.014476371478 len of mem:2000 spent:3.832512617111206\n",
      "round:176 score: -420.52055712550015 mean:-511.5004655891972 len of mem:2000 spent:5.107067346572876\n",
      "round:177 score: -243.99891498936034 mean:-510.0060435188071 len of mem:2000 spent:3.56125545501709\n",
      "round:178 score: -1396.9873258512566 mean:-514.9337173095429 len of mem:2000 spent:9.190293788909912\n",
      "round:179 score: -583.071318345595 mean:-515.3101681439962 len of mem:2000 spent:5.351545333862305\n",
      "round:180 score: -525.5882626137643 mean:-515.3666411905334 len of mem:2000 spent:4.973635911941528\n",
      "round:181 score: -268.1710380476697 mean:-514.015845544944 len of mem:2000 spent:4.14478063583374\n",
      "round:182 score: -479.26996933330935 mean:-513.8270092611851 len of mem:2000 spent:3.6145143508911133\n",
      "round:183 score: -295.84291391962046 mean:-512.6487168539335 len of mem:2000 spent:4.418025732040405\n",
      "round:184 score: -291.5795220372271 mean:-511.460172795779 len of mem:2000 spent:3.558373212814331\n",
      "round:185 score: -502.65995067744933 mean:-511.4131127844511 len of mem:2000 spent:4.22583532333374\n",
      "round:186 score: -1026.894961634739 mean:-514.1550375123782 len of mem:2000 spent:10.068334341049194\n",
      "round:187 score: -800.2027280598455 mean:-515.6685173565446 len of mem:2000 spent:6.413269996643066\n",
      "round:188 score: -580.699716804631 mean:-516.010786827324 len of mem:2000 spent:7.951895713806152\n",
      "round:189 score: -1681.330972228036 mean:-522.1119396304692 len of mem:2000 spent:11.485412120819092\n",
      "round:190 score: -485.30819116904473 mean:-521.920253440566 len of mem:2000 spent:4.362184524536133\n",
      "round:191 score: -1387.340624504664 mean:-526.404296813955 len of mem:2000 spent:10.245206117630005\n",
      "round:192 score: -401.93359580616163 mean:-525.7626952623685 len of mem:2000 spent:3.2955970764160156\n",
      "round:193 score: -104.01342938216348 mean:-523.5998785142648 len of mem:2000 spent:2.341155529022217\n",
      "round:194 score: -644.6631156728045 mean:-524.2175480916043 len of mem:2000 spent:5.812868356704712\n",
      "round:195 score: -514.17003895784 mean:-524.166545507169 len of mem:2000 spent:4.546112775802612\n",
      "round:196 score: -544.1901289302796 mean:-524.2676747163766 len of mem:2000 spent:5.732052564620972\n",
      "round:197 score: -360.8526166426264 mean:-523.446493520026 len of mem:2000 spent:3.1083948612213135\n",
      "round:198 score: -1041.8433528565051 mean:-526.0384778167085 len of mem:2000 spent:9.708600997924805\n",
      "round:199 score: -694.7928088744363 mean:-526.8780516030654 len of mem:2000 spent:5.742457389831543\n",
      "round:200 score: -1083.3980406833734 mean:-529.6331010539581 len of mem:2000 spent:10.11039924621582\n",
      "round:201 score: -1108.228685509983 mean:-532.4833256079286 len of mem:2000 spent:7.859596490859985\n",
      "round:202 score: -580.4334377317357 mean:-532.718375177163 len of mem:2000 spent:5.104869365692139\n",
      "round:203 score: -441.89457883857125 mean:-532.2753322681942 len of mem:2000 spent:4.387006044387817\n",
      "round:204 score: -418.71225391173266 mean:-531.724055188794 len of mem:2000 spent:5.142822265625\n",
      "round:205 score: -469.0823084401318 mean:-531.4214380547425 len of mem:2000 spent:3.656191110610962\n",
      "round:206 score: -558.0365666640147 mean:-531.5493954038253 len of mem:2000 spent:5.184511661529541\n",
      "round:207 score: -149.71390505999892 mean:-529.7224313351946 len of mem:2000 spent:5.5480451583862305\n",
      "round:208 score: -674.0322737237706 mean:-530.4096210608545 len of mem:2000 spent:5.731602191925049\n",
      "round:209 score: -288.5343151384183 mean:-529.2632925967671 len of mem:2000 spent:4.15444278717041\n",
      "round:210 score: -377.8277933882428 mean:-528.548974204274 len of mem:2000 spent:3.7253148555755615\n",
      "round:211 score: -420.6251525758634 mean:-528.04228959569 len of mem:2000 spent:3.577727794647217\n",
      "round:212 score: -325.2792848512878 mean:-527.0947989193143 len of mem:2000 spent:3.777276039123535\n",
      "round:213 score: -455.584780925617 mean:-526.7621941844599 len of mem:2000 spent:3.3161518573760986\n",
      "round:214 score: -516.9564228692085 mean:-526.7167970950375 len of mem:2000 spent:5.066623210906982\n",
      "round:215 score: -363.05899661083816 mean:-525.9626136826679 len of mem:2000 spent:3.868274211883545\n",
      "round:216 score: -490.0994359255547 mean:-525.7981036929564 len of mem:2000 spent:4.534493446350098\n",
      "round:217 score: -363.645136590421 mean:-525.0576791856388 len of mem:2000 spent:6.16290020942688\n",
      "round:218 score: -464.7220806515606 mean:-524.7834264650294 len of mem:2000 spent:5.78536319732666\n",
      "round:219 score: -613.7547247406962 mean:-525.1860115251002 len of mem:2000 spent:4.735335826873779\n",
      "round:220 score: -305.241323596018 mean:-524.1952696875818 len of mem:2000 spent:3.7301578521728516\n",
      "round:221 score: -396.09758950642 mean:-523.6208406284734 len of mem:2000 spent:3.4716107845306396\n",
      "round:222 score: -387.56176134845 mean:-523.0134340245448 len of mem:2000 spent:4.103555917739868\n",
      "round:223 score: -759.8020848640243 mean:-524.0658280282759 len of mem:2000 spent:6.191533327102661\n",
      "round:224 score: -434.5882018867269 mean:-523.6699093285345 len of mem:2000 spent:3.529038190841675\n",
      "round:225 score: -504.00771893211765 mean:-523.5832917496956 len of mem:2000 spent:6.043358087539673\n",
      "round:226 score: -985.555678802406 mean:-525.6094864297514 len of mem:2000 spent:9.221752166748047\n",
      "round:227 score: -466.92401100758775 mean:-525.3532179781263 len of mem:2000 spent:4.105061292648315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:228 score: -346.82755067560487 mean:-524.577019424637 len of mem:2000 spent:3.6058568954467773\n",
      "round:229 score: -623.9425014671688 mean:-525.0071730265528 len of mem:2000 spent:4.9218833446502686\n",
      "round:230 score: -425.0000524200089 mean:-524.5761078515245 len of mem:2000 spent:3.731381416320801\n",
      "round:231 score: -362.24462227151633 mean:-523.8794061966747 len of mem:2000 spent:3.770700454711914\n",
      "round:232 score: -735.1205242525289 mean:-524.7821460174263 len of mem:2000 spent:5.436336994171143\n",
      "round:233 score: -433.20712649852584 mean:-524.3924650833033 len of mem:2000 spent:3.6005494594573975\n",
      "round:234 score: -296.89255651821975 mean:-523.4284824198919 len of mem:2000 spent:3.646378517150879\n",
      "round:235 score: -714.0679838355572 mean:-524.2328685018146 len of mem:2000 spent:9.115435123443604\n",
      "round:236 score: -1105.1583038099816 mean:-526.6737316753782 len of mem:2000 spent:8.080748558044434\n",
      "round:237 score: -1399.5623397930415 mean:-530.3259852658288 len of mem:2000 spent:10.802088975906372\n",
      "round:238 score: -410.55180977209966 mean:-529.8269262012715 len of mem:2000 spent:3.378638505935669\n",
      "round:239 score: -580.7904379856942 mean:-530.0383930551487 len of mem:2000 spent:5.021226167678833\n",
      "round:240 score: -1755.7915315943533 mean:-535.1034886689471 len of mem:2000 spent:11.42464804649353\n",
      "round:241 score: -435.82984582293886 mean:-534.6949551592927 len of mem:2000 spent:4.0148680210113525\n",
      "round:242 score: -510.1190576789311 mean:-534.5942342679798 len of mem:2000 spent:4.079138278961182\n",
      "round:243 score: -613.1311107454169 mean:-534.9147929474796 len of mem:2000 spent:7.72833514213562\n",
      "round:244 score: -412.2415798126287 mean:-534.4161213493704 len of mem:2000 spent:3.337153911590576\n",
      "round:245 score: -288.0601216094538 mean:-533.4187286378727 len of mem:2000 spent:5.713277339935303\n",
      "round:246 score: -439.93295247281844 mean:-533.0417698630138 len of mem:2000 spent:4.457656383514404\n",
      "round:247 score: -564.7862238260964 mean:-533.1692576299337 len of mem:2000 spent:4.349042892456055\n",
      "round:248 score: -461.95104895378967 mean:-532.884384795229 len of mem:2000 spent:3.6751482486724854\n",
      "round:249 score: -380.119208266745 mean:-532.2757585939204 len of mem:2000 spent:3.9659013748168945\n",
      "round:250 score: -661.5036701117116 mean:-532.7885677666101 len of mem:2000 spent:5.8356616497039795\n",
      "round:251 score: -556.1690764141387 mean:-532.8809808442683 len of mem:2000 spent:6.323915481567383\n",
      "round:252 score: -464.35098802881595 mean:-532.6111777229477 len of mem:2000 spent:4.209059953689575\n",
      "round:253 score: -289.5955349976508 mean:-531.6581752024563 len of mem:2000 spent:3.5653176307678223\n",
      "round:254 score: -364.53039383961044 mean:-531.0053323065076 len of mem:2000 spent:4.2292914390563965\n",
      "round:255 score: -381.8438039923388 mean:-530.4249372547016 len of mem:2000 spent:6.082550048828125\n",
      "round:256 score: -1384.9218096072987 mean:-533.7369406359132 len of mem:2000 spent:10.263962030410767\n",
      "round:257 score: -700.5947589829177 mean:-534.3811793167896 len of mem:2000 spent:5.870436429977417\n",
      "round:258 score: -574.4280098833872 mean:-534.5352055881996 len of mem:2000 spent:5.358614683151245\n",
      "round:259 score: -667.4515868828762 mean:-535.0444637540796 len of mem:2000 spent:7.339172840118408\n",
      "round:260 score: -559.22662038268 mean:-535.1367620618223 len of mem:2000 spent:3.5731050968170166\n",
      "round:261 score: -478.52830718156525 mean:-534.9215207885134 len of mem:2000 spent:4.094562530517578\n",
      "round:262 score: -696.8113654777118 mean:-535.5347398971845 len of mem:2000 spent:6.300832748413086\n",
      "round:263 score: -519.5584375102954 mean:-535.4744519636491 len of mem:2000 spent:6.768522262573242\n",
      "round:264 score: -239.00192198391449 mean:-534.3598935802667 len of mem:2000 spent:4.493146896362305\n",
      "round:265 score: -425.1913870227155 mean:-533.9510227691898 len of mem:2000 spent:3.915175676345825\n",
      "round:266 score: -362.48554175283346 mean:-533.3112261982332 len of mem:2000 spent:3.754330635070801\n",
      "round:267 score: -2947.030745788121 mean:-542.2841612152959 len of mem:2000 spent:17.84413242340088\n",
      "round:268 score: -265.8646053013351 mean:-541.2603850822812 len of mem:2000 spent:3.5513787269592285\n",
      "round:269 score: -414.1109984252319 mean:-540.7911991536574 len of mem:2000 spent:3.77107310295105\n",
      "round:270 score: -2673.52986203971 mean:-548.6321501201502 len of mem:2000 spent:14.972193241119385\n",
      "round:271 score: -340.53666835555356 mean:-547.869895608192 len of mem:2000 spent:4.771530389785767\n",
      "round:272 score: -352.04398980153366 mean:-547.1552025213064 len of mem:2000 spent:4.601028203964233\n",
      "round:273 score: -416.5194013409046 mean:-546.6801632442867 len of mem:2000 spent:4.797133922576904\n",
      "round:274 score: -701.903188814616 mean:-547.2425655108459 len of mem:2000 spent:5.05804443359375\n",
      "round:275 score: -327.1993080872149 mean:-546.4481855201469 len of mem:2000 spent:3.9208216667175293\n",
      "round:276 score: -529.0581255563201 mean:-546.3856313476151 len of mem:2000 spent:4.848195314407349\n",
      "round:277 score: -514.9604087830675 mean:-546.2729961412906 len of mem:2000 spent:4.866612434387207\n",
      "round:278 score: -502.3628451563529 mean:-546.1161741734873 len of mem:2000 spent:4.2903313636779785\n",
      "round:279 score: -877.9470195694475 mean:-547.2970668617291 len of mem:2000 spent:7.757545709609985\n",
      "round:280 score: -745.4107991239886 mean:-547.9995978271982 len of mem:2000 spent:6.8329854011535645\n",
      "round:281 score: -661.2293867759669 mean:-548.3997030885012 len of mem:2000 spent:5.9970862865448\n",
      "round:282 score: -312.3648014550631 mean:-547.5685942799327 len of mem:2000 spent:5.452336549758911\n",
      "round:283 score: -674.2906645158401 mean:-548.0132331228658 len of mem:2000 spent:5.943382978439331\n",
      "round:284 score: -485.02019753382126 mean:-547.7929777536732 len of mem:2000 spent:3.99159836769104\n",
      "round:285 score: -1122.0051242378736 mean:-549.7937169400294 len of mem:2000 spent:8.086434364318848\n",
      "round:286 score: -434.53726703869046 mean:-549.3935209334276 len of mem:2000 spent:3.4205331802368164\n",
      "round:287 score: -417.12527268096846 mean:-548.9358453339381 len of mem:2000 spent:3.7011020183563232\n",
      "round:288 score: -461.37412836521383 mean:-548.6339083788736 len of mem:2000 spent:5.747895240783691\n",
      "round:289 score: -404.822159144854 mean:-548.1397099278976 len of mem:2000 spent:3.7509100437164307\n",
      "round:290 score: -438.48776889653925 mean:-547.7641895818997 len of mem:2000 spent:3.63523006439209\n",
      "round:291 score: -291.0574762530545 mean:-546.8880574544975 len of mem:2000 spent:3.023780584335327\n",
      "round:292 score: -478.92957812596984 mean:-546.6569061642645 len of mem:2000 spent:3.0434436798095703\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6080e5f00e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mexplore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#         print(\"diff:\", reward - prev_reward,\"prev:\", prev_reward, \" current:\", reward, \"total reward:\", total_reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-46fe9031b0d8>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "state_size = 8\n",
    "action_size = 4\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "# agent.load_model()\n",
    "done = False\n",
    "batch_size = 32\n",
    "game_history = [0]\n",
    "\n",
    "# game_history = np.load(\"game_history.npy\")\n",
    "explore = True\n",
    "t_steps = 0\n",
    "for e in range(10000):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "#     print(state.shape)\n",
    "    total_reward = 0\n",
    "    prev_reward = 0\n",
    "    start = time.time()\n",
    "    for timee in range(450):\n",
    "        # env.render()\n",
    "#         if time % 5 == 0:\n",
    "#             print(time, end=', ')\n",
    "        \n",
    "\n",
    "        \n",
    "        action = agent.act(state)\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "#         print(action, end='')\n",
    "#         if done :\n",
    "#             done = True\n",
    "#             reward = -100\n",
    "        \n",
    "\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        prev_reward = reward\n",
    "        total_reward += reward\n",
    "        if len(agent.memory) > 1000:\n",
    "            agent.replay(batch_size)\n",
    "            explore = False\n",
    "#         print(\"diff:\", reward - prev_reward,\"prev:\", prev_reward, \" current:\", reward, \"total reward:\", total_reward)\n",
    "\n",
    "\n",
    "    game_history.append(total_reward)\n",
    "#     if explore == False:\n",
    "    print(\"round:{} score: {} mean:{} len of mem:{} spent:{}\".format(e, total_reward, np.mean(game_history), len(agent.memory), time.time() - start))\n",
    "        \n",
    "    if e % 10 == 4:\n",
    "        agent.save_model()\n",
    "        np.save(\"game_history\", game_history)\n",
    "\n",
    "    done = False\n",
    "\n",
    "        \n",
    "np.save(\"positive_scene\",agent.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "324"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
