{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import *\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test,y_test) = mnist.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train,10)\n",
    "y_test = np_utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 4)         104       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 8)         808       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 16)          3216      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 3, 3, 32)          12832     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 31,850\n",
      "Trainable params: 31,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Conv2D(4, (5,5), padding='same', input_shape=(28,28,1)))\n",
    "m.add(Activation('relu'))\n",
    "m.add(MaxPool2D(pool_size=(2,2)))\n",
    "m.add(Conv2D(8, (5,5), padding='same'))\n",
    "m.add(Activation('relu'))\n",
    "m.add(MaxPool2D(pool_size=(2,2)))\n",
    "m.add(Conv2D(16, (5,5), padding='same'))\n",
    "m.add(Activation('relu'))\n",
    "m.add(MaxPool2D(pool_size=(2,2)))\n",
    "m.add(Conv2D(32, (5,5), padding='same'))\n",
    "m.add(Activation('relu'))\n",
    "m.add(MaxPool2D(pool_size=(2,2)))\n",
    "m.add(Flatten())\n",
    "m.add(Dense(128))\n",
    "m.add(Activation('relu'))\n",
    "\n",
    "m.add(Dense(64))\n",
    "m.add(Activation('relu'))\n",
    "\n",
    "m.add(Dense(32))\n",
    "m.add(Activation('relu'))\n",
    "\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_acc',patience=8,baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 11s 234us/step - loss: 0.3432 - acc: 0.8884 - val_loss: 0.1173 - val_acc: 0.9651\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 10s 215us/step - loss: 0.1053 - acc: 0.9672 - val_loss: 0.0904 - val_acc: 0.9716\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0787 - acc: 0.9755 - val_loss: 0.0736 - val_acc: 0.9792\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 10s 215us/step - loss: 0.0662 - acc: 0.9789 - val_loss: 0.0712 - val_acc: 0.9781\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0571 - acc: 0.9826 - val_loss: 0.0700 - val_acc: 0.9793\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0493 - acc: 0.9846 - val_loss: 0.0570 - val_acc: 0.9848\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 10s 216us/step - loss: 0.0435 - acc: 0.9868 - val_loss: 0.0586 - val_acc: 0.9839\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0394 - acc: 0.9874 - val_loss: 0.0673 - val_acc: 0.9807\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 11s 219us/step - loss: 0.0347 - acc: 0.9895 - val_loss: 0.0624 - val_acc: 0.9829\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 10s 218us/step - loss: 0.0327 - acc: 0.9898 - val_loss: 0.0614 - val_acc: 0.9840\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 10s 216us/step - loss: 0.0304 - acc: 0.9906 - val_loss: 0.0676 - val_acc: 0.9802\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 10s 216us/step - loss: 0.0252 - acc: 0.9924 - val_loss: 0.0585 - val_acc: 0.9865\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 10s 216us/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0629 - val_acc: 0.9837\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 10s 216us/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0582 - val_acc: 0.9857\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0236 - acc: 0.9929 - val_loss: 0.0620 - val_acc: 0.9832\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 10s 216us/step - loss: 0.0216 - acc: 0.9935 - val_loss: 0.0620 - val_acc: 0.9838\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 10s 218us/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0625 - val_acc: 0.9844\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 10s 218us/step - loss: 0.0207 - acc: 0.9932 - val_loss: 0.0551 - val_acc: 0.9874\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0163 - acc: 0.9946 - val_loss: 0.0693 - val_acc: 0.9852\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 11s 233us/step - loss: 0.0201 - acc: 0.9941 - val_loss: 0.0731 - val_acc: 0.9845\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0174 - acc: 0.9947 - val_loss: 0.0596 - val_acc: 0.9844\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 10s 214us/step - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0690 - val_acc: 0.9864\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0686 - val_acc: 0.9864\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 10s 216us/step - loss: 0.0169 - acc: 0.9948 - val_loss: 0.0667 - val_acc: 0.9853\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 10s 215us/step - loss: 0.0135 - acc: 0.9960 - val_loss: 0.0703 - val_acc: 0.9857\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0132 - acc: 0.9961 - val_loss: 0.0665 - val_acc: 0.9865\n"
     ]
    }
   ],
   "source": [
    "hist = m.fit(x_train,y_train,batch_size=32, validation_split=0.2, callbacks=[es],epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2e13db0bf0b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 58us/step\n",
      "score 0.988000\n"
     ]
    }
   ],
   "source": [
    "score = m.evaluate(x_test,y_test)\n",
    "print('score %lf'%score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 4)         104       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 8)         808       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 16)        3216      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,458\n",
      "Trainable params: 228,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Conv2D(4, (5,5), padding='same', input_shape=(28,28,1)))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Conv2D(8, (5,5), padding='same'))\n",
    "m.add(Activation('relu'))\n",
    "m.add(MaxPool2D(pool_size=(2,2)))\n",
    "m.add(Conv2D(16, (5,5), padding='same'))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Conv2D(32, (5,5), padding='same'))\n",
    "m.add(Activation('relu'))\n",
    "m.add(MaxPool2D(pool_size=(2,2)))\n",
    "m.add(Flatten())\n",
    "m.add(Dense(128))\n",
    "m.add(Activation('relu'))\n",
    "\n",
    "m.add(Dense(64))\n",
    "m.add(Activation('relu'))\n",
    "\n",
    "m.add(Dense(32))\n",
    "m.add(Activation('relu'))\n",
    "\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 12s 240us/step - loss: 0.1898 - acc: 0.9400 - val_loss: 0.0506 - val_acc: 0.9853\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 0.0588 - acc: 0.9830 - val_loss: 0.0546 - val_acc: 0.9838\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 11s 219us/step - loss: 0.0423 - acc: 0.9867 - val_loss: 0.0508 - val_acc: 0.9848\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 11s 223us/step - loss: 0.0325 - acc: 0.9898 - val_loss: 0.0457 - val_acc: 0.9878\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 11s 221us/step - loss: 0.0260 - acc: 0.9920 - val_loss: 0.0398 - val_acc: 0.9890\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 10s 217us/step - loss: 0.0222 - acc: 0.9934 - val_loss: 0.0523 - val_acc: 0.9864\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 11s 223us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0513 - val_acc: 0.9861\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0418 - val_acc: 0.9888\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 11s 221us/step - loss: 0.0165 - acc: 0.9955 - val_loss: 0.0391 - val_acc: 0.9907\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 10s 218us/step - loss: 0.0151 - acc: 0.9956 - val_loss: 0.0437 - val_acc: 0.9885\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 11s 221us/step - loss: 0.0130 - acc: 0.9961 - val_loss: 0.0474 - val_acc: 0.9904\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 11s 221us/step - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0543 - val_acc: 0.9891\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 10s 219us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0457 - val_acc: 0.9905\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 11s 219us/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0469 - val_acc: 0.9892\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 0.0106 - acc: 0.9969 - val_loss: 0.0464 - val_acc: 0.9902\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 11s 221us/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.0474 - val_acc: 0.9902\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 11s 221us/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0577 - val_acc: 0.9900\n"
     ]
    }
   ],
   "source": [
    "m.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "hist = m.fit(x_train,y_train,batch_size=32, validation_split=0.2, callbacks=[es],epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 68us/step\n",
      "score 0.991700\n"
     ]
    }
   ],
   "source": [
    "score = m.evaluate(x_test,y_test)\n",
    "print('score %lf'%score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
