{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "ZsSwxy6ZPu6I",
    "outputId": "f95fd03f-96d4-4cb1-998c-a9e95e1b470d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.16.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 3.4MB/s \n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.16.3\n",
      "    Uninstalling numpy-1.16.3:\n",
      "      Successfully uninstalled numpy-1.16.3\n",
      "Successfully installed numpy-1.16.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "!pip3 install numpy==1.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RWe4u5sFPwiE"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=200)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=200)\n",
    "# x_train = normalize(x_train)\n",
    "# x_test = normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWqP0TxCPy8K"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, BatchNormalization, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "KJPVzLytQY8Z",
    "outputId": "171f2aea-bbf9-4370-9a48-60ae947bb8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 80)          800000    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, None, 80)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30)                13320     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 25)                775       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 25)                100       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 815,271\n",
      "Trainable params: 815,161\n",
      "Non-trainable params: 110\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N = 80\n",
    "K = 30\n",
    "\n",
    "m = Sequential()\n",
    "m.add(Embedding(10000,N))\n",
    "m.add(Dropout(0.25))\n",
    "\n",
    "m.add(LSTM(K,dropout=0.25 , recurrent_dropout=0.25))\n",
    "\n",
    "m.add(Dense(30))\n",
    "m.add(BatchNormalization())\n",
    "m.add(Activation('relu'))\n",
    "\n",
    "m.add(Dense(25))\n",
    "m.add(BatchNormalization())\n",
    "m.add(Activation('relu'))\n",
    "\n",
    "\n",
    "m.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "m.summary()\n",
    "## 5 lstm neuron * (5+20) + 4 = 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "9srHbXMEQcNB",
    "outputId": "f6d88ef6-f30c-4248-c9f9-6155136474f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 119s 6ms/step - loss: 0.5746 - acc: 0.6820 - val_loss: 0.4921 - val_acc: 0.7582\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 115s 6ms/step - loss: 0.3925 - acc: 0.8265 - val_loss: 0.4263 - val_acc: 0.7978\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 114s 6ms/step - loss: 0.3446 - acc: 0.8495 - val_loss: 0.4444 - val_acc: 0.7840\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 114s 6ms/step - loss: 0.3029 - acc: 0.8720 - val_loss: 0.4246 - val_acc: 0.8026\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 114s 6ms/step - loss: 0.2929 - acc: 0.8784 - val_loss: 0.4388 - val_acc: 0.8030\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 114s 6ms/step - loss: 0.2337 - acc: 0.9058 - val_loss: 0.4487 - val_acc: 0.8288\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 115s 6ms/step - loss: 0.1977 - acc: 0.9216 - val_loss: 0.4716 - val_acc: 0.8240\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 114s 6ms/step - loss: 0.2282 - acc: 0.9089 - val_loss: 0.4436 - val_acc: 0.8178\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 114s 6ms/step - loss: 0.1579 - acc: 0.9411 - val_loss: 0.5321 - val_acc: 0.8048\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 116s 6ms/step - loss: 0.1441 - acc: 0.9462 - val_loss: 0.4785 - val_acc: 0.8214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc418049b00>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=10, batch_size=32,validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nBbeVtaUQ1X9",
    "outputId": "7a06c576-60ad-4cc8-834e-6d6dccfc61dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 21s 848us/step\n",
      "loss 0.47156350796699525 acc: 0.83004\n"
     ]
    }
   ],
   "source": [
    "score = m.evaluate(x_test, y_test)\n",
    "print('loss', score[0], 'acc:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPDJyY6qS28o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
