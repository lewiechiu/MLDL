{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from lunarLanding import DQNAgent\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "state_size = 8\n",
    "action_size = 4\n",
    "agent = DQNAgent(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 50)                450       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 4)                 204       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 6,354\n",
      "Trainable params: 6,054\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "m.add(Dense(50, input_dim = 8))\n",
    "m.add(Activation('sigmoid'))\n",
    "m.add(BatchNormalization())\n",
    "\n",
    "m.add(Dense(50))\n",
    "m.add(Activation('sigmoid'))\n",
    "m.add(BatchNormalization())\n",
    "\n",
    "m.add(Dense(50))\n",
    "m.add(Activation('sigmoid'))\n",
    "m.add(BatchNormalization())\n",
    "\n",
    "m.add(Dense(4))\n",
    "m.add(Activation('softmax'))\n",
    "\n",
    "m.compile(loss='categorical_crossentropy', optimizer=Adam(lr = 0.0001))\n",
    "m.summary()\n",
    "\n",
    "agent.model = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epi:0 score: 46.55964489130862 mean:23.27982244565431 spent:0.011180639266967773\n",
      "epi:1 score: -165.103726824286 mean:-39.51469397765913 spent:0.013939142227172852\n",
      "epi:2 score: -80.88649949138733 mean:-49.85764535609118 spent:0.020031452178955078\n",
      "epi:3 score: -216.8535231002165 mean:-83.25682090491625 spent:0.019986867904663086\n",
      "epi:4 score: -96.04966253792725 mean:-85.38896117708475 spent:0.013978242874145508\n",
      "epi:5 score: 30.18237156285373 mean:-68.87877078566497 spent:0.007879257202148438\n",
      "epi:6 score: -61.759177073392195 mean:-67.98882157163087 spent:0.018883228302001953\n",
      "epi:7 score: -302.9642787096113 mean:-94.09720569807314 spent:0.01488804817199707\n",
      "epi:8 score: -252.82184527982676 mean:-109.9696696562485 spent:0.021493196487426758\n",
      "epi:9 score: -6.964397340173548 mean:-100.60555399115077 spent:0.008044719696044922\n",
      "epi:10 score: -104.26490102172417 mean:-100.91049957703189 spent:0.013003826141357422\n",
      "epi:11 score: -19.33707803501946 mean:-94.63562099687708 spent:0.01421046257019043\n",
      "epi:12 score: 47.215363625405914 mean:-84.50340780957116 spent:0.020518779754638672\n",
      "epi:13 score: -136.77608505412002 mean:-87.98825295920776 spent:0.009767532348632812\n",
      "epi:14 score: -28.335624307143583 mean:-84.25996366845374 spent:0.009019136428833008\n",
      "epi:15 score: -229.47925017306306 mean:-92.80227463931311 spent:0.023856401443481445\n",
      "epi:16 score: 65.88976310470122 mean:-83.9860503202012 spent:0.02490830421447754\n",
      "epi:17 score: -60.766712721357294 mean:-82.76397992026205 spent:0.016280412673950195\n",
      "epi:18 score: -73.85478082384715 mean:-82.31851996544131 spent:0.009680509567260742\n",
      "epi:19 score: -310.8691373858712 mean:-93.20188269974749 spent:0.015330791473388672\n",
      "epi:20 score: -120.47832609327716 mean:-94.44172103581701 spent:0.009719371795654297\n",
      "epi:21 score: -3.5836578240407597 mean:-90.49137046139197 spent:8.883331775665283\n",
      "epi:22 score: 18.781295383395996 mean:-85.93834271785914 spent:6.016415119171143\n",
      "epi:23 score: 86.23178944728933 mean:-79.0515374312532 spent:8.915981531143188\n",
      "epi:24 score: -57.635318842267395 mean:-78.22783671629222 spent:10.846566200256348\n",
      "epi:25 score: 33.19459893916948 mean:-74.101079840164 spent:8.574092388153076\n",
      "epi:26 score: -67.7082629646326 mean:-73.87276495175216 spent:10.939037084579468\n",
      "epi:27 score: -28.479070073831842 mean:-72.3074651283756 spent:7.222909212112427\n",
      "epi:28 score: 43.007416919581644 mean:-68.46363572677701 spent:9.407901287078857\n",
      "epi:29 score: -119.82273321540049 mean:-70.12038080705518 spent:7.993417263031006\n",
      "epi:30 score: 15.009151903260364 mean:-67.46008290985785 spent:6.439136743545532\n",
      "epi:31 score: 23.24403531162883 mean:-64.71147326678249 spent:5.9269678592681885\n",
      "epi:32 score: -102.95008509738825 mean:-65.83613832062383 spent:10.949787855148315\n",
      "epi:33 score: 123.32122340687417 mean:-60.431642271266746 spent:13.106237173080444\n",
      "epi:34 score: -29.552669999896985 mean:-59.573893041506466 spent:9.282726526260376\n",
      "epi:35 score: -76.40341982381402 mean:-60.02874511670397 spent:14.368543863296509\n",
      "epi:36 score: -11.601844241559164 mean:-58.754352988410695 spent:8.209086656570435\n",
      "epi:37 score: -84.10589251019336 mean:-59.4043924633282 spent:9.121283292770386\n",
      "epi:38 score: -20.042773801045414 mean:-58.42035199677112 spent:7.733412742614746\n",
      "epi:39 score: 36.15894684000595 mean:-56.11353983002045 spent:5.85445499420166\n",
      "epi:40 score: 51.75514221775926 mean:-53.54523787650188 spent:13.872574090957642\n",
      "epi:41 score: -70.76858824364588 mean:-53.94578090829593 spent:9.034677267074585\n",
      "epi:42 score: -152.27758197774025 mean:-56.18059456896512 spent:10.843125343322754\n",
      "epi:43 score: -93.41336535535414 mean:-57.00798947532932 spent:10.28035831451416\n",
      "epi:44 score: -15.403160512950691 mean:-56.10353667179935 spent:7.027362823486328\n",
      "epi:45 score: -46.080820722340036 mean:-55.890287396278936 spent:6.865905523300171\n",
      "epi:46 score: 54.43111269769717 mean:-53.59192489432112 spent:7.78060507774353\n",
      "epi:47 score: -153.0103117334606 mean:-55.62087156450764 spent:8.873860359191895\n",
      "epi:48 score: -176.5411890411676 mean:-58.03927791404083 spent:9.525570631027222\n",
      "epi:49 score: -17.797306646014555 mean:-57.25021965388345 spent:9.952128887176514\n",
      "epi:50 score: 35.71427301026516 mean:-55.462440948803675 spent:5.911967515945435\n",
      "epi:51 score: -72.86180231382978 mean:-55.79073078587963 spent:6.357452392578125\n",
      "epi:52 score: -29.134229656841768 mean:-55.29709187608264 spent:7.782822370529175\n",
      "epi:53 score: -12.433103598000548 mean:-54.51774663466296 spent:7.518502235412598\n",
      "epi:54 score: -161.29875114410441 mean:-56.42455028661728 spent:9.523528575897217\n",
      "epi:55 score: 83.68277268047787 mean:-53.96652707666825 spent:8.387906312942505\n",
      "epi:56 score: -19.908219211914105 mean:-53.37931487210352 spent:8.677510261535645\n",
      "epi:57 score: -205.95277538343794 mean:-55.96530572822784 spent:8.492394208908081\n",
      "epi:58 score: -68.04567435687802 mean:-56.166645205372006 spent:6.315969944000244\n",
      "epi:59 score: -26.583167112546946 mean:-55.68167015466996 spent:7.3361523151397705\n",
      "epi:60 score: -135.2308269342409 mean:-56.96472107046949 spent:7.698792457580566\n",
      "epi:61 score: -20.972451123973375 mean:-56.39341519830288 spent:6.081035852432251\n",
      "epi:62 score: -21.68010428910121 mean:-55.851019715346595 spent:6.65681529045105\n",
      "epi:63 score: -74.05118480733782 mean:-56.131022255223385 spent:5.737729072570801\n",
      "epi:64 score: -162.70922859903177 mean:-57.745843563462905 spent:9.066055297851562\n",
      "epi:65 score: -94.60954516977307 mean:-58.29604806504962 spent:9.118207931518555\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-7860d581d480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mexplore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#         print(\"diff:\", reward - prev_reward,\"prev:\", prev_reward, \" current:\", reward, \"total reward:\", total_reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLDL/Lunar Landing Final Project/lunarLanding.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "done = False\n",
    "batch_size = 64\n",
    "game_history = [0]\n",
    "\n",
    "\n",
    "explore = True\n",
    "t_steps = 0\n",
    "for episode in range(1000):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "#     print(state.shape)\n",
    "    total_reward = 0\n",
    "    prev_reward = 0\n",
    "    start = time.time()\n",
    "    for timee in range(450):\n",
    "        # env.render()\n",
    "#         if time % 5 == 0:\n",
    "#             print(time, end=', ')\n",
    "        \n",
    "\n",
    "#         print(state)\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        prev_reward = reward\n",
    "        total_reward += reward\n",
    "        if len(agent.memory) > 1000:\n",
    "            agent.replay(batch_size)\n",
    "            explore = False\n",
    "#         print(\"diff:\", reward - prev_reward,\"prev:\", prev_reward, \" current:\", reward, \"total reward:\", total_reward)\n",
    "\n",
    "\n",
    "    game_history.append(total_reward)\n",
    "#     if explore == False:\n",
    "    if len(game_history) > 35:\n",
    "        print(\"epi:{} score: {} mean:{} spent:{}\".format(episode, total_reward, np.mean(game_history[-30:-1]), time.time() - start))\n",
    "    else:\n",
    "        print(\"epi:{} score: {}spent:{}\".format(episode, total_reward, time.time() - start))\n",
    "        \n",
    "    if episode % 10 == 9:\n",
    "        agent.save_model()\n",
    "        np.save(\"game_history\", game_history)\n",
    "\n",
    "    done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: ([0, 0, 0, 0.8],)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1e90300dd4a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2126\u001b[0m         \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2128\u001b[0;31m         \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: ([0, 0, 0, 0.8],)"
     ]
    }
   ],
   "source": [
    "log_loss([0,0,0,0.8],[0.9,0.05,0.02,0.03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
